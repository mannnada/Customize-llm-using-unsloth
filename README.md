# Customize-llm-using-unsloth
# ü¶ô LLM Fine-Tuning with Unsloth AI

This project shows how to **fine-tune**, **pretrain**, and **deploy** open-source LLMs using **Unsloth AI**. Each part is covered with easy-to-use **Colab notebooks** and **YouTube videos**.

---

## üìò What You‚Äôll Learn

- Fine-tune models using **LoRA**
- Continue pretraining on new data
- Train with **reward models** like ORPO & DPO
- Extend model context
- Export models to **Ollama**

---

## üìÅ Project Parts

### üîπ Part A: Fine-Tuning

| Model              | Task            | Colab     | Video     |
|--------------------|-----------------|-----------|-----------|
| LLaMA 3.1 (8B)     | Coding Assistant| https://colab.research.google.com/drive/1qNjrvdEJc0INlEG2u5oeHzkTGg6sX_Qx?usp=sharing| [Video](#)|
| Mistral NeMo (12B) | Chatbot         | [https://colab.research.google.com/drive/1PEYGLGUGG2K0q7en__rgBZ90RW-ETHC_?usp=sharing](#)| [Video](#)|
| Gemma 2 (9B)       | Conversation    | [https://colab.research.google.com/drive/1JfA2oa9HuK6HKMqWtnupBY53eqWYHuXd?usp=sharing](#)| [Video](#)|
| Phi-3              | Reasoning       | [https://colab.research.google.com/drive/1Iwa18DqUa9sCTZysgEx56OnfBuCe4Qvc?usp=sharing](#)| [Video](#)|

---

### üîπ Part B: Continued Pretraining

| Task                | Colab     | Video     |
|---------------------|-----------|-----------|
| New Language/Data   | [https://colab.research.google.com/drive/1Iwa18DqUa9sCTZysgEx56OnfBuCe4Qvc?usp=sharing](#)| [Video](#)|

---

### üîπ Part C: Chat Templates

| Type                    | Colab     |
|-------------------------|-----------|
| Classification Chat     | [https://colab.research.google.com/drive/1mxOpr2dI5uq4CROJqZMVE_KwlNeVaYFZ?usp=sharing](#)|
| Conversational Chat     | [https://colab.research.google.com/drive/17wnR91ddyu3bm1ykfL6idX2s2DgX4ryB?usp=sharing](#)|
| Long Context (TinyLlama)| [https://colab.research.google.com/drive/1jPJSR6x_LNhEto6D6KCZdwb9F6otXjy-?usp=sharing](#)|
| Multi-dataset Finetune  | [https://colab.research.google.com/drive/1wivnUsvpW1PfJhdA8Z6JJbd32grzNTuy?usp=sharing](#)|

---

### üîπ Part D: Reward Modeling

| Method | Colab     | Video     |
|--------|-----------|-----------|
| ORPO   | [https://colab.research.google.com/drive/1o_RFxervMZvI9KP1ksXDjKucHufb_iMM?usp=sharing](#)| [Video](#)|
| DPO    | [https://colab.research.google.com/drive/13oQHiC9YAK2WtcH8AB4YXXJ-r10lQvTJ?usp=sharing](#)| [Video](#)|

---

### üîπ Part E: Custom Checkpoint Finetuning

| Colab     | Video     |
|-----------|-----------|
| [https://colab.research.google.com/drive/1v4Xh7yvafVrvv5iyqiYHhHXauO0LTjp8?usp=sharing](#)| [Video](#)|

---

### üîπ Part F: Mental Health Chatbot

| Colab     | Video     |
|-----------|-----------|
| [https://colab.research.google.com/drive/1M71dvc-TfE8O2s0V038qjdQ-zfEiQ6K9?usp=sharing](#)| [Video](#)|

---

### üîπ Part G: Export to Ollama

| Colab     | Video     |
|-----------|-----------|
| [https://colab.research.google.com/drive/1C5XhbgBZS7fXsbADELhot1t_uk0bGOMl?usp=sharing](#)| [Video](#)|

---

## ‚≠ê Why Use This?

- Easy LLM finetuning with **Unsloth AI**
- Ready-to-use notebooks
- Real-world examples
- Fast and lightweight setup

---

